{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcc82dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code for ingestion of the dataset\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "# Locate repo root and Data folder\n",
    "\n",
    "def find_repo_root(start_path=None):\n",
    "    \"\"\"Walk up directories until .git is found\"\"\"\n",
    "    p = Path(start_path or Path.cwd()).resolve()\n",
    "    for parent in [p] + list(p.parents):\n",
    "        if (parent / \".git\").exists():\n",
    "            return parent\n",
    "    # fallback to current working directory\n",
    "    return p\n",
    "\n",
    "REPO_ROOT = find_repo_root()\n",
    "DATA_DIR = REPO_ROOT / \"Data\"\n",
    "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Output file (csv inside a zip)\n",
    "output_file = \"stock_symbols_chris_testing2.csv.zip\"\n",
    "output_path = DATA_DIR / output_file\n",
    "\n",
    "\n",
    "# SEC Parameters\n",
    "\n",
    "SEC_URL = \"https://www.sec.gov/files/company_tickers_exchange.json\"\n",
    "SEC_HEADERS = {\"User-Agent\": \"YourAppName your_email@example.com\"}  # required by SEC\n",
    "\n",
    "def get_universe_from_sec(limit):\n",
    "    r = requests.get(SEC_URL, headers=SEC_HEADERS, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    df = pd.DataFrame(j[\"data\"], columns=j[\"fields\"])\n",
    "    df = df.rename(columns={\"ticker\": \"symbol\", \"name\": \"company_name\"})\n",
    "    df[\"symbol\"] = df[\"symbol\"].str.upper()\n",
    "    return df[[\"symbol\", \"company_name\"]].drop_duplicates().head(limit)\n",
    "\n",
    "def yf_fetch_info(symbol: str) -> dict:\n",
    "    candidates = [symbol, symbol.replace(\"-\", \".\")]\n",
    "    for sym in candidates:\n",
    "        try:\n",
    "            t = yf.Ticker(sym)\n",
    "            info = t.get_info()\n",
    "            if info and isinstance(info, dict) and info.get(\"quoteType\") in (\"EQUITY\", \"ETF\"):\n",
    "                return info\n",
    "        except Exception:\n",
    "            pass\n",
    "    return {}\n",
    "\n",
    "def build_base_table(limit, sleep_s=0.35):\n",
    "    universe = get_universe_from_sec(limit=limit)\n",
    "    print(\"Symbols pulled:\", len(universe.index))\n",
    "    rows = []\n",
    "    count = 0\n",
    "    for sym in universe[\"symbol\"].tolist():\n",
    "        rows.append(yf_fetch_info(sym))\n",
    "        count += 1\n",
    "        time.sleep(sleep_s)\n",
    "        if count % 200 == 0:\n",
    "            print(f\"{count} rows completed\")\n",
    "\n",
    "    facts = pd.DataFrame(rows)\n",
    "\n",
    "    df_cols = list(facts.columns)\n",
    "    added = [\"symbol\", \"company_name\"]\n",
    "    cols = df_cols + added\n",
    "\n",
    "    base = (\n",
    "        universe\n",
    "        .merge(facts, on=\"symbol\", how=\"left\")\n",
    "        [cols]\n",
    "        .drop_duplicates(subset=[\"symbol\"])\n",
    "    )\n",
    "    return base\n",
    "\n",
    "# -------------------------------\n",
    "# Run + Save\n",
    "# -------------------------------\n",
    "df_base = build_base_table(limit=200, sleep_s=0.35)\n",
    "\n",
    "print(df_base.head(10))\n",
    "print(df_base.shape)\n",
    "print(df_base.columns)\n",
    "\n",
    "# Save as CSV inside a zip\n",
    "df_base.to_csv(output_path, index=False, compression=\"zip\")\n",
    "print(f\"Saved: {output_path}\")\n",
    "\n",
    "# Load later (same folder)\n",
    "df = pd.read_csv(output_path, compression=\"zip\")\n",
    "grouped = df.groupby(\"sector\")[\"sector\"].count()\n",
    "print(grouped)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
