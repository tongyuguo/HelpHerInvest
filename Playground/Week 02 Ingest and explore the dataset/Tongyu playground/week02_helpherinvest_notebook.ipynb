{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "aff58d9e",
   "metadata": {},
   "source": [
    "Code for ingestion of the dataset\n",
    "Code for exploration of the dataset\n",
    "The code should be organized logically with appropriate comments\n",
    "Best practice: someone who is completely unfamiliar with your project and code can easily understand what you have done and run the code error-free. \n",
    "The code must run error-free.\n",
    "Clearly mark where the week starts and ends."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "127fb100",
   "metadata": {},
   "source": [
    "# Ingestion of Dataset\n",
    "## it takes more than an hour to run the code below, so we have triple quoted this section, and in the exploration sectioin the data is pulled from github where we ingested it with the code below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008641f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Go to repo\n",
    "%cd /home/jupyter-toomeyck/HelpHerInvest\n",
    "#Sync latest from GitHub before editing\n",
    "!git pull --rebase origin main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bc97a",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Imports\n",
    "# libraries\n",
    "\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "#need to install yfinance\n",
    "%pip install yfinance --quiet\n",
    "import yfinance as yf\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import warnings\n",
    "import zipfile\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c91b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "## PARAMETERS ##\n",
    "## CHANGE OUTPUT PATH ##\n",
    "\n",
    "repo_root = Path(\"/home/jupyter-toomeyck/HelpHerInvest\")\n",
    "output_path = repo_root / \"Data\" / \"stock_symbols_new.csv.zip\"\n",
    "output_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "output_file = \"stock_symbols_new.csv.zip\"\n",
    "\n",
    "SEC_URL = \"https://www.sec.gov/files/company_tickers_exchange.json\"\n",
    "SEC_HEADERS = {\"User-Agent\": \"YourAppName your_email@example.com\"}  # required by SEC\n",
    "\n",
    "\n",
    "def get_universe_from_sec(limit):\n",
    "    r = requests.get(SEC_URL, headers=SEC_HEADERS, timeout=30)\n",
    "    r.raise_for_status()\n",
    "    j = r.json()\n",
    "    df = pd.DataFrame(j[\"data\"], columns=j[\"fields\"])\n",
    "    df = df.rename(columns={\"ticker\": \"symbol\", \"name\": \"company_name\"})\n",
    "    df[\"symbol\"] = df[\"symbol\"].str.upper()\n",
    "    return df[[\"symbol\", \"company_name\"]].drop_duplicates()\n",
    "\n",
    "def yf_fetch_info(symbol: str) -> dict:\n",
    "    # Normalize common Yahoo symbol formatting\n",
    "    # BRK-B on SEC often needs BRK-B or BRK.B depending; yfinance likes BRK-B *sometimes* but BRK.B often works.\n",
    "    # We'll try a small fallback.\n",
    "    candidates = [symbol, symbol.replace(\"-\", \".\")]\n",
    "    for sym in candidates:\n",
    "        try:\n",
    "            t = yf.Ticker(sym)\n",
    "            info = t.get_info()  # yfinance >= 0.2.0 style\n",
    "            if info and isinstance(info, dict) and info.get(\"quoteType\") in (\"EQUITY\", \"ETF\"):\n",
    "                return info\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    return info\n",
    "\n",
    "def build_base_table(limit, sleep_s=0.35):\n",
    "    universe = get_universe_from_sec(limit=limit)\n",
    "    print(\"Symbols pulled:\",len(universe.index))\n",
    "    rows = []\n",
    "    count = 0\n",
    "    for sym in universe[\"symbol\"].tolist():\n",
    "        rows.append(yf_fetch_info(sym))\n",
    "        count += 1\n",
    "        time.sleep(sleep_s)  # throttle to avoid Yahoo blocks\n",
    "        if count % 200 == 0:\n",
    "            print(\"{} rows completed\".format(count))\n",
    "\n",
    "    facts = pd.DataFrame(rows)\n",
    "\n",
    "    df_cols = list(facts.columns)\n",
    "    added = [\"symbol\", \"company_name\"]\n",
    "    cols = df_cols + added\n",
    "\n",
    "    base = (\n",
    "        universe\n",
    "        .merge(facts, on=\"symbol\", how=\"left\")\n",
    "        [cols]\n",
    "        .drop_duplicates(subset=[\"symbol\"])\n",
    "    )\n",
    "\n",
    "    return base\n",
    "\n",
    "df_base = build_base_table(limit=1000, sleep_s=0.35)\n",
    "#universe = get_universe_from_sec(limit=2000)\n",
    "#print(universe)\n",
    "#df_base = pd.DataFrame()\n",
    "\n",
    "print(df_base.head(10))\n",
    "print(df_base.shape)\n",
    "print(df_base.columns)\n",
    "\n",
    "## CHANGE THE OUTPUT PATH ##\n",
    "\n",
    "df_base.to_csv(output_path,index=False)\n",
    "df = pd.read_csv(output_path)\n",
    "\n",
    "grouped = df.groupby(\"sector\")[\"sector\"].count()\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc40ff3e",
   "metadata": {},
   "source": [
    "# Dependent and Independent Variables"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
